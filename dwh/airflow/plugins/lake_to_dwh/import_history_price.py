import os
import io
import time
import pandas as pd
from datetime import datetime
import psycopg2
from sqlalchemy import create_engine
from concurrent.futures import ProcessPoolExecutor

# --- C·∫§U H√åNH (D·ª±a tr√™n ·∫£nh c·ªßa b·∫°n) ---
DB_CONFIG = {
    "dbname": "postgres",
    "user": "admin",
    "pass": "123456",
    "host": "localhost",
    "port": "5432",
    "schema": "hethong_phantich_chungkhoan",
    "table": "history_price"
}
FOLDER_PATH = "2026-01-01"

def check_connection():
    """Ki·ªÉm tra k·∫øt n·ªëi DB tr∆∞·ªõc khi ch·∫°y"""
    print(f"[{datetime.now().strftime('%H:%M:%S')}] üîç ƒêang ki·ªÉm tra k·∫øt n·ªëi t·ªõi Database...")
    try:
        conn = psycopg2.connect(
            dbname=DB_CONFIG['dbname'], 
            user=DB_CONFIG['user'], 
            password=DB_CONFIG['pass'], 
            host=DB_CONFIG['host'], 
            port=DB_CONFIG['port'],
            connect_timeout=5
        )
        cursor = conn.cursor()
        cursor.execute("SELECT version();")
        db_version = cursor.fetchone()
        print(f"‚úÖ K·∫øt n·ªëi th√†nh c√¥ng! Phi√™n b·∫£n DB: {db_version[0]}")
        cursor.close()
        conn.close()
        return True
    except Exception as e:
        print(f"‚ùå K·∫øt n·ªëi th·∫•t b·∫°i: {e}")
        return False

def fast_copy_worker(file_info):
    """Worker x·ª≠ l√Ω t·ª´ng file"""
    file_path, current_idx, total_files = file_info
    file_name = os.path.basename(file_path)
    start_time = time.time()
    
    prefix = f"[{current_idx}/{total_files}]"
    print(f"{prefix} üöÄ ƒêang b·∫Øt ƒë·∫ßu: {file_name}")

    try:
        # ƒê·ªçc d·ªØ li·ªáu
        df = pd.read_csv(file_path)
        row_count = len(df)
        df['import_time'] = datetime.now()
        
        # Chuy·ªÉn sang buffer ƒë·ªÉ d√πng l·ªánh COPY (t·ªëc ƒë·ªô cao nh·∫•t)
        output = io.StringIO()
        df.to_csv(output, index=False, header=False)
        output.seek(0)
        
        # K·∫øt n·ªëi v√† th·ª±c thi
        conn = psycopg2.connect(
            dbname=DB_CONFIG['dbname'], user=DB_CONFIG['user'], 
            password=DB_CONFIG['pass'], host=DB_CONFIG['host'], port=DB_CONFIG['port']
        )
        cursor = conn.cursor()
        
        copy_sql = f"COPY {DB_CONFIG['schema']}.{DB_CONFIG['table']} FROM STDIN WITH CSV"
        cursor.copy_expert(sql=copy_sql, file=output)
        
        conn.commit()
        cursor.close()
        conn.close()
        
        duration = round(time.time() - start_time, 2)
        return f"{prefix} ‚úÖ Xong: {file_name} | {row_count} d√≤ng | {duration}s"
    
    except Exception as e:
        return f"{prefix} ‚ùå L·ªói t·∫°i {file_name}: {e}"

def main():
    # 1. Ki·ªÉm tra k·∫øt n·ªëi tr∆∞·ªõc
    if not check_connection():
        return

    # 2. Qu√©t th∆∞ m·ª•c
    if not os.path.exists(FOLDER_PATH):
        print(f"‚ùå Th∆∞ m·ª•c '{FOLDER_PATH}' kh√¥ng t·ªìn t·∫°i.")
        return

    csv_files = [os.path.join(FOLDER_PATH, f) for f in os.listdir(FOLDER_PATH) if f.endswith('.csv')]
    total = len(csv_files)
    
    if total == 0:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file CSV n√†o ƒë·ªÉ x·ª≠ l√Ω.")
        return

    print(f"[{datetime.now().strftime('%H:%M:%S')}] üìÇ T√¨m th·∫•y {total} files. B·∫Øt ƒë·∫ßu ƒë·∫©y d·ªØ li·ªáu d√πng ƒëa nh√¢n...")
    print("-" * 60)

    # Chu·∫©n b·ªã d·ªØ li·ªáu cho worker (ƒë√≠nh k√®m index ƒë·ªÉ log ti·∫øn tr√¨nh)
    file_tasks = [(csv_files[i], i + 1, total) for i in range(total)]

    # 3. Ch·∫°y ƒëa ti·∫øn tr√¨nh
    # max_workers: n√™n ƒë·ªÉ kho·∫£ng 2-4 t√πy c·∫•u h√¨nh m√°y ƒë·ªÉ tr√°nh kh√≥a b·∫£ng (deadlock)
    with ProcessPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(fast_copy_worker, file_tasks))

    print("-" * 60)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] üèÅ HO√ÄN TH√ÄNH T·∫§T C·∫¢.")
    for res in results:
        print(res)

if __name__ == "__main__":
    main()